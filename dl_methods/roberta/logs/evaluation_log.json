{
  "timestamp": "2025-11-29T03:43:43.986804",
  "model_name": "RoBERTa",
  "best_hyperparameters": {
    "learning_rate": 2e-05,
    "batch_size": 32,
    "epochs": 5,
    "max_len": 128,
    "warmup_steps": 500
  },
  "best_validation_accuracy": 0.987389574482433,
  "metrics": {
    "test_accuracy": 0.9875092836405375,
    "test_precision_weighted": 0.9875328653027331,
    "test_recall_weighted": 0.9875092836405375,
    "test_f1_weighted": 0.9875016813538009
  },
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5
    ],
    "train_loss": [
      0.10422267937643691,
      0.03484033023707858,
      0.020225557457103072,
      0.011442787681883563,
      0.005958721490233427
    ],
    "train_acc": [
      0.9568752617668722,
      0.9886339018789445,
      0.993919787409194,
      0.9967793648271978,
      0.9984257881890787
    ],
    "val_loss": [
      0.061610229008786925,
      0.04087095847014631,
      0.04952253818778288,
      0.056900361397483404,
      0.06073725779266044
    ],
    "val_acc": [
      0.980443725133185,
      0.9869849618989818,
      0.9867826556072561,
      0.9873221390518578,
      0.9874570099130083
    ]
  },
  "confusion_matrix": [
    [
      8321,
      60
    ],
    [
      125,
      6305
    ]
  ],
  "classification_report": "              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      8381\n           1       0.99      0.98      0.99      6430\n\n    accuracy                           0.99     14811\n   macro avg       0.99      0.99      0.99     14811\nweighted avg       0.99      0.99      0.99     14811\n"
}