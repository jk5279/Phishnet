{
  "timestamp": "2025-11-29T04:36:27.761625",
  "model_name": "DistilBERT",
  "best_hyperparameters": {
    "learning_rate": 2e-05,
    "batch_size": 32,
    "epochs": 5,
    "max_len": 128,
    "warmup_steps": 500
  },
  "best_validation_accuracy": 0.986175736732079,
  "metrics": {
    "test_accuracy": 0.9844034838971035,
    "test_precision_weighted": 0.9844397016005916,
    "test_recall_weighted": 0.9844034838971035,
    "test_f1_weighted": 0.9843915572051677
  },
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5
    ],
    "train_loss": [
      0.12363313878120341,
      0.03459968487258704,
      0.016740801660832475,
      0.008971316631194359,
      0.0046680878583414895
    ],
    "train_acc": [
      0.9471267023873139,
      0.9891682673560462,
      0.9947429990901344,
      0.9974148264756431,
      0.9987579613234933
    ],
    "val_loss": [
      0.06823039069673416,
      0.05744898264285815,
      0.06286717281586632,
      0.06692136709881229,
      0.07259739334216615
    ],
    "val_acc": [
      0.9761952930069459,
      0.9819947400364152,
      0.9834108840784949,
      0.9840852383842471,
      0.9836131903702205
    ]
  },
  "confusion_matrix": [
    [
      8306,
      75
    ],
    [
      156,
      6274
    ]
  ],
  "classification_report": "              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99      8381\n           1       0.99      0.98      0.98      6430\n\n    accuracy                           0.98     14811\n   macro avg       0.98      0.98      0.98     14811\nweighted avg       0.98      0.98      0.98     14811\n"
}